"""
Training_XFL_SmallData - TEEå†…éƒ¨ä½¿ç”¨å°æ•°æ®é›†çš„æ¶æ„æ£€æµ‹ç®—æ³•
åŸºäºTEEå¯ä¿¡æ‰§è¡Œç¯å¢ƒçš„æ¶æ„å®¢æˆ·ç«¯æ£€æµ‹æ–¹æ¡ˆ - èµ„æºä¼˜åŒ–ç‰ˆæœ¬

æ ¸å¿ƒæ”¹è¿›:
- TEEå†…éƒ¨ä½¿ç”¨é‡‡æ ·æ•°æ®é›†ï¼ˆè€Œéå®Œæ•´æ•°æ®ï¼‰
- è°ƒæ•´TEEè®­ç»ƒè¶…å‚æ•°ä»¥ä¿æŒæ£€æµ‹æ•ˆæœ
- ä¿æŒå¤–éƒ¨è®­ç»ƒä¸å˜
- ä¿æŒæ‰€æœ‰æ£€æµ‹åŠŸèƒ½å’Œæ•°æ®æ”¶é›†åŠŸèƒ½
"""

# Standard library imports
import copy
import random
from collections import defaultdict
from datetime import datetime

# Third-party imports
import numpy as np
import torch
from torch.utils.data import DataLoader, Subset
from tqdm import tqdm

# Local application imports
import sys
import os
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from models import vgg_16_bn, test, MobileNetV2
from models.Fed import Aggregation, summon_clients
from models.Update import DatasetSplit
from models.standard_resnet18 import standard_resnet18
from models.resnet20 import resnet20
from models.lenet5 import LeNet5
from wandbUtils import init_run, endrun, upload_data
from data_collector import (
    initialize_data_collector, collect_round_data, collect_attack_data, 
    collect_detection_data, save_experiment_data, add_log
)

# å¯¼å…¥æ”»å‡»æ¨¡å—
from attacks.attack_manager import AttackManager
from attacks.config import ATTACK_SCENARIOS

layer_idx = 0


def getStandardNet(args):
    """è·å–æ ‡å‡†æ¨¡å‹"""
    if args.model == "resnet":
        net = standard_resnet18(
            num_classes=args.num_classes, 
            num_channels=args.num_channels, 
            track_running_stats=False
        ).to(args.device)
        return net
    elif args.model == "resnet20":
        net = resnet20(
            num_classes=args.num_classes,
            num_channels=args.num_channels,
            track_running_stats=False
        ).to(args.device)
        return net
    elif args.model == "lenet5":
        net = LeNet5(
            num_classes=args.num_classes,
            num_channels=args.num_channels,
            track_running_stats=False
        ).to(args.device)
        return net
    elif args.model == "vgg":
        net = vgg_16_bn(
            num_classes=args.num_classes,
            track_running_stats=False,
            num_channels=args.num_channels
        ).to(args.device)
        return net
    elif args.model == "mobilenet":
        net = MobileNetV2(
            channels=args.num_channels,
            num_classes=args.num_classes,
            trs=False,
            rate=[1] * 9
        ).to(args.device)
        return net
    else:
        raise ValueError(f"Unknown model: {args.model}. Only standard models (resnet, resnet20, lenet5, vgg, mobilenet) are supported.")


class LocalUpdate_XFL_SmallData(object):
    """
    XFLæœ¬åœ°è®­ç»ƒç±» - TEEä½¿ç”¨å°æ•°æ®é›†ä¼˜åŒ–ç‰ˆæœ¬
    
    æ ¸å¿ƒæ”¹è¿›ï¼š
    1. TEEå†…éƒ¨ä½¿ç”¨åˆ†å±‚é‡‡æ ·çš„å°æ•°æ®é›†
    2. è°ƒæ•´TEEè®­ç»ƒè½®æ¬¡ä»¥ä¿æŒå‚æ•°æ›´æ–°æ¬¡æ•°ä¸€è‡´
    3. ä¿æŒå¤–éƒ¨è®­ç»ƒä¸å˜
    """
    def __init__(self, args, dataset, idxs, verbose=False, tee_sample_ratio=0.3):
        """
        Args:
            args: å‚æ•°é…ç½®
            dataset: çœŸå®æ•°æ®é›†
            idxs: å®¢æˆ·ç«¯æ•°æ®ç´¢å¼•
            verbose: æ˜¯å¦è¯¦ç»†è¾“å‡º
            tee_sample_ratio: TEEæ•°æ®é‡‡æ ·æ¯”ä¾‹ï¼ˆé»˜è®¤30%ï¼‰
        """
        self.args = args
        self.loss_func = torch.nn.CrossEntropyLoss()
        self.dataset = dataset
        self.idxs = idxs
        self.verbose = verbose
        
        # TEEé‡‡æ ·é…ç½®
        self.tee_sample_ratio = tee_sample_ratio
        
        # åˆ†å±‚é‡‡æ ·TEEæ•°æ®ç´¢å¼•
        self.tee_idxs = self._stratified_sampling(dataset, idxs, tee_sample_ratio)
        
        # è®¡ç®—TEEè®­ç»ƒè½®æ¬¡ï¼ˆä¿æŒæ€»æ›´æ–°æ¬¡æ•°ä¸€è‡´ï¼‰
        # TEEå†…éƒ¨è®­ç»ƒepochsï¼šé™ä½å€æ•°é¿å…GPUå‹åŠ›ç´¯ç§¯
        # åŸæ–¹æ¡ˆï¼š20 / 0.3 = 67 epochs â†’ é•¿æ—¶é—´è®­ç»ƒï¼Œ51è½®åCUDAå´©æºƒ
        # æ–°æ–¹æ¡ˆï¼š20 / 0.3 * 0.6 = 40 epochs â†’ å¹³è¡¡æ•ˆæœä¸ç¨³å®šæ€§
        self.tee_local_ep = int(args.local_ep / tee_sample_ratio * 0.6)
        
        # å¤–éƒ¨è®­ç»ƒä½¿ç”¨å®Œæ•´æ•°æ®
        self.external_data = DataLoader(
            DatasetSplit(dataset, idxs, self.args),
            batch_size=self.args.local_bs, 
            shuffle=True, 
            drop_last=True
        )
        
        # TEEè®­ç»ƒä½¿ç”¨é‡‡æ ·æ•°æ®
        self.clean_data = DataLoader(
            DatasetSplit(dataset, self.tee_idxs, self.args),
            batch_size=self.args.local_bs, 
            shuffle=True, 
            drop_last=True
        )
        
        if verbose:
            print(f"  æ•°æ®é…ç½®:")
            print(f"    å¤–éƒ¨æ•°æ®: {len(idxs)} æ ·æœ¬")
            print(f"    TEEæ•°æ®: {len(self.tee_idxs)} æ ·æœ¬ ({tee_sample_ratio*100:.0f}%)")
            print(f"    å¤–éƒ¨è®­ç»ƒ: {args.local_ep} epochs")
            print(f"    TEEè®­ç»ƒ: {self.tee_local_ep} epochs")
    
    def _stratified_sampling(self, dataset, idxs, ratio):
        """
        åˆ†å±‚éšæœºé‡‡æ · - æŒ‰ç±»åˆ«æ¯”ä¾‹é‡‡æ ·
        
        Args:
            dataset: æ•°æ®é›†
            idxs: ç´¢å¼•åˆ—è¡¨
            ratio: é‡‡æ ·æ¯”ä¾‹
        
        Returns:
            sampled_idxs: é‡‡æ ·åçš„ç´¢å¼•åˆ—è¡¨
        """
        # è·å–æ ‡ç­¾
        labels = []
        for idx in idxs:
            if hasattr(dataset, 'targets'):
                labels.append(dataset.targets[idx])
            elif hasattr(dataset, 'labels'):
                labels.append(dataset.labels[idx])
            else:
                # å¦‚æœæ²¡æœ‰ç›´æ¥çš„æ ‡ç­¾å±æ€§ï¼Œé€šè¿‡ç´¢å¼•è·å–
                _, label = dataset[idx]
                labels.append(label)
        
        # æŒ‰ç±»åˆ«åˆ†ç»„
        class_indices = defaultdict(list)
        for i, label in enumerate(labels):
            class_indices[int(label)].append(idxs[i])
        
        # æ¯ç±»é‡‡æ ·
        sampled_idxs = []
        for label, indices in class_indices.items():
            n_samples = max(1, int(len(indices) * ratio))
            sampled = random.sample(indices, n_samples)
            sampled_idxs.extend(sampled)
        
        return sampled_idxs
    
    def train_external(self, round, external_model, client_id=None, attack_manager=None, global_model=None):
        """
        å¤–éƒ¨è®­ç»ƒ - ä½¿ç”¨å®Œæ•´æ¨¡å‹å’Œå®Œæ•´æ•°æ®ï¼ˆå¯èƒ½è¢«æ±¡æŸ“ï¼‰
        
        Args:
            round: å½“å‰è®­ç»ƒè½®æ¬¡
            external_model: å¤–éƒ¨æ¨¡å‹
            client_id: å®¢æˆ·ç«¯ID
            attack_manager: æ”»å‡»ç®¡ç†å™¨
            global_model: å…¨å±€æ¨¡å‹ï¼ˆç”¨äºFedProxï¼Œå¯é€‰ï¼‰
        """
        from optimizer.Adabelief import AdaBelief
        
        # ç¡®ä¿æ¨¡å‹åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        external_model = external_model.to(self.args.device)
        external_model.train()
        
        # å¦‚æœä½¿ç”¨FedProxä¸”æä¾›äº†å…¨å±€æ¨¡å‹ï¼Œä¿å­˜å…¨å±€æ¨¡å‹å‚æ•°
        use_fedprox = global_model is not None and hasattr(self.args, 'use_fedprox') and self.args.use_fedprox
        if use_fedprox:
            global_params = {name: param.clone().detach() for name, param in global_model.named_parameters()}
        
        # å¤–éƒ¨è®­ç»ƒä¼˜åŒ–å™¨
        if self.args.optimizer == 'sgd':
            optimizer = torch.optim.SGD(
                external_model.parameters(), 
                lr=self.args.lr * (self.args.lr_decay ** round),
                momentum=self.args.momentum, 
                weight_decay=self.args.weight_decay
            )
        elif self.args.optimizer == 'adam':
            optimizer = torch.optim.Adam(external_model.parameters(), lr=self.args.lr)
        elif self.args.optimizer == 'adaBelief':
            optimizer = AdaBelief(external_model.parameters(), lr=self.args.lr)

        external_loss = 0
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæ¶æ„å®¢æˆ·ç«¯
        is_malicious = attack_manager and attack_manager.is_malicious(client_id)
        
        # å¤–éƒ¨è®­ç»ƒï¼ˆä½¿ç”¨args.local_epï¼Œä¸å˜ï¼‰
        for epoch in range(self.args.local_ep):
            for batch_idx, (images, labels) in enumerate(self.external_data):
                try:
                    images, labels = images.to(self.args.device), labels.to(self.args.device)
                    
                    # å¦‚æœæ˜¯æ¶æ„å®¢æˆ·ç«¯ï¼Œæ•°æ®è¢«æ±¡æŸ“
                    if is_malicious:
                        images, labels = attack_manager.poison_data(client_id, images, labels)
                    
                    # å¤–éƒ¨è®­ç»ƒ
                    external_model.zero_grad()
                    log_probs = external_model(images)['output']
                    loss = self.loss_func(log_probs, labels)
                    
                    # FedProx: æ·»åŠ proximal term
                    if use_fedprox:
                        proximal_term = 0.0
                        for name, param in external_model.named_parameters():
                            if name in global_params:
                                proximal_term += ((param - global_params[name]) ** 2).sum()
                        loss += (self.args.prox_alpha / 2) * proximal_term
                    
                    loss.backward()
                    optimizer.step()
                    external_loss += loss.item()
                    
                except RuntimeError as e:
                    if "CUDA" in str(e):
                        print(f"âŒ CUDAé”™è¯¯åœ¨Client {client_id}, epoch {epoch}, batch {batch_idx}: {e}")
                        print(f"ğŸ’¥ CUDAé”™è¯¯æ£€æµ‹åˆ°ï¼Œç«‹å³åœæ­¢ç¨‹åºæ‰§è¡Œ")
                        print(f"ğŸ”§ å»ºè®®ï¼šé‡å¯Pythonè¿›ç¨‹æˆ–é‡å¯æœåŠ¡å™¨")
                        raise e  # ç«‹å³æŠ›å‡ºé”™è¯¯ï¼Œåœæ­¢ç¨‹åº
                    else:
                        raise e
            
            # ğŸ”§ ä¼˜åŒ–: æ¯10è½®epochåæ¸…ç†GPUç¼“å­˜ï¼Œé˜²æ­¢å†…å­˜ç¢ç‰‡åŒ–å’ŒcuDNNçŠ¶æ€æŸå
            if (epoch + 1) % 10 == 0 and self.args.device == 'cuda':
                torch.cuda.empty_cache()
                torch.cuda.synchronize()

        if self.verbose:
            attack_info = " [MALICIOUS-EXTERNAL]" if is_malicious else " [BENIGN-EXTERNAL]"
            info = '\nClient {} {} External Loss={:.4f}'.format(
                client_id, attack_info,
                external_loss / (self.args.local_ep * len(self.external_data))
            )
            print(info)

        return external_model.state_dict(), external_loss

    def train_tee_secure(self, round, tee_model, client_id=None, attack_manager=None, global_model=None):
        """
        TEEå®‰å…¨è®­ç»ƒ - ä½¿ç”¨å®Œæ•´æ¨¡å‹å’Œé‡‡æ ·çš„å¹²å‡€æ•°æ®
        å…³é”®æ”¹è¿›ï¼šä½¿ç”¨è°ƒæ•´åçš„è®­ç»ƒè½®æ¬¡ï¼ˆself.tee_local_epï¼‰
        æ–°å¢ï¼šæ”¯æŒFedProxï¼Œä¸å®¢æˆ·ç«¯è®­ç»ƒä¿æŒä¸€è‡´
        """
        from optimizer.Adabelief import AdaBelief
        
        # ç¡®ä¿æ¨¡å‹åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        tee_model = tee_model.to(self.args.device)
        tee_model.train()
        
        # FedProx: ä¿å­˜å…¨å±€æ¨¡å‹å‚æ•°ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        use_fedprox = global_model is not None and hasattr(self.args, 'use_fedprox') and self.args.use_fedprox
        if use_fedprox:
            global_params = {name: param.clone().detach() 
                           for name, param in global_model.state_dict().items()}
            prox_mu = self.args.prox_alpha if hasattr(self.args, 'prox_alpha') else 0.01
        
        # TEEå†…éƒ¨ä¼˜åŒ–å™¨
        if self.args.optimizer == 'sgd':
            optimizer = torch.optim.SGD(
                tee_model.parameters(), 
                lr=self.args.lr * (self.args.lr_decay ** round),
                momentum=self.args.momentum, 
                weight_decay=self.args.weight_decay
            )
        elif self.args.optimizer == 'adam':
            optimizer = torch.optim.Adam(tee_model.parameters(), lr=self.args.lr)
        elif self.args.optimizer == 'adaBelief':
            optimizer = AdaBelief(tee_model.parameters(), lr=self.args.lr)

        Predict_loss = 0
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæ¶æ„å®¢æˆ·ç«¯ï¼ˆä»…ç”¨äºæ—¥å¿—ï¼‰
        is_malicious = attack_manager and attack_manager.is_malicious(client_id)
        
        # TEEè®­ç»ƒï¼ˆä½¿ç”¨è°ƒæ•´åçš„è½®æ¬¡ï¼‰
        for epoch in range(self.tee_local_ep):
            for batch_idx, (images, labels) in enumerate(self.clean_data):
                try:
                    images, labels = images.to(self.args.device), labels.to(self.args.device)
                    
                    # TEEå†…éƒ¨è®­ç»ƒï¼ˆä¸å—å¤–éƒ¨æ”»å‡»å½±å“ï¼‰
                    tee_model.zero_grad()
                    log_probs = tee_model(images)['output']
                    ce_loss = self.loss_func(log_probs, labels)
                    
                    # FedProx: æ·»åŠ proximal termï¼ˆä¸å®¢æˆ·ç«¯è®­ç»ƒä¿æŒä¸€è‡´ï¼‰
                    if use_fedprox:
                        proximal_term = 0.0
                        for name, param in tee_model.named_parameters():
                            if name in global_params:
                                proximal_term += torch.sum((param - global_params[name]) ** 2)
                        loss = ce_loss + (prox_mu / 2.0) * proximal_term
                    else:
                        loss = ce_loss
                    
                    loss.backward()
                    optimizer.step()
                    Predict_loss += loss.item()
                    
                    # æ”¶é›†æ”»å‡»äº‹ä»¶æ•°æ®
                    if is_malicious:
                        collect_attack_data(round, client_id, "tee_protected", {
                            "batch_size": len(labels),
                            "tee_protection": True,
                            "attack_blocked": True,
                            "tee_sample_ratio": self.tee_sample_ratio
                        })
                        
                except RuntimeError as e:
                    if "CUDA" in str(e):
                        print(f"âŒ TEEè®­ç»ƒCUDAé”™è¯¯åœ¨Client {client_id}, epoch {epoch}, batch {batch_idx}: {e}")
                        print(f"ğŸ’¥ CUDAé”™è¯¯æ£€æµ‹åˆ°ï¼Œç«‹å³åœæ­¢ç¨‹åºæ‰§è¡Œ")
                        print(f"ğŸ”§ å»ºè®®ï¼šé‡å¯Pythonè¿›ç¨‹æˆ–é‡å¯æœåŠ¡å™¨")
                        raise e  # ç«‹å³æŠ›å‡ºé”™è¯¯ï¼Œåœæ­¢ç¨‹åº
                    else:
                        raise e
            
            # ğŸ”§ ä¼˜åŒ–: æ¯10è½®epochåæ¸…ç†GPUç¼“å­˜ï¼Œé˜²æ­¢å†…å­˜ç¢ç‰‡åŒ–å’ŒcuDNNçŠ¶æ€æŸå
            if (epoch + 1) % 10 == 0 and self.args.device == 'cuda':
                torch.cuda.empty_cache()
                torch.cuda.synchronize()

        if self.verbose:
            attack_info = " [MALICIOUS-TEE-PROTECTED]" if is_malicious else " [BENIGN]"
            info = '\nClient {} {} TEE Loss={:.4f} (epochs={})'.format(
                client_id, attack_info,
                Predict_loss / (self.tee_local_ep * len(self.clean_data)),
                self.tee_local_ep
            )
            print(info)

        return tee_model.state_dict(), Predict_loss


def Training_XFL_SmallData(args, dataset_train, dataset_test, dict_users, attack_scenario='no_attack'):
    """
    XFLè®­ç»ƒå‡½æ•° - TEEä½¿ç”¨å°æ•°æ®é›†ä¼˜åŒ–ç‰ˆæœ¬
    
    æ ¸å¿ƒæ”¹è¿›ï¼š
    - TEEå†…éƒ¨ä½¿ç”¨30%é‡‡æ ·æ•°æ®
    - è°ƒæ•´TEEè®­ç»ƒè½®æ¬¡ä»¥ä¿æŒæ£€æµ‹æ•ˆæœ
    - ä¿æŒæ‰€æœ‰å…¶ä»–åŠŸèƒ½ä¸å˜
    
    Args:
        attack_scenario: æ”»å‡»åœºæ™¯ ('no_attack', 'label_flipping', 'noise_injection', 'backdoor')
    """
    # åˆå§‹åŒ–å…¨å±€æ¨¡å‹
    global_model = getStandardNet(args)
    model_params = sum(p.numel() for p in global_model.parameters() if p.requires_grad)
    init_msg = f"ğŸŒ æœåŠ¡å™¨åˆå§‹åŒ–: æ ‡å‡†ResNet18å…¨å±€æ¨¡å‹, å‚æ•°æ•°: {model_params:,}"
    print(init_msg)
    add_log(init_msg, "info")
    
    # TEEé…ç½®ä¿¡æ¯
    tee_sample_ratio = 0.3
    tee_msg = f"ğŸ”§ TEEé…ç½®: é‡‡æ ·æ¯”ä¾‹={tee_sample_ratio*100:.0f}%, è®­ç»ƒè½®æ¬¡è°ƒæ•´={int(args.local_ep/tee_sample_ratio)}è½®"
    print(tee_msg)
    add_log(tee_msg, "info")
    
    # åˆå§‹åŒ–wandb
    if hasattr(args, 'wandb') and args.wandb:
        run = init_run(args, "XFL-SmallData-Experiment", attack_scenario)
    else:
        run = None
    
    # åˆå§‹åŒ–æ”»å‡»ç®¡ç†å™¨
    attack_config = ATTACK_SCENARIOS.get(attack_scenario, ATTACK_SCENARIOS['no_attack'])
    attack_config['attack_params']['num_classes'] = args.num_classes
    attack_manager = AttackManager(args.num_users, attack_config)
    
    attack_msg = f"ğŸ¯ æ”»å‡»åœºæ™¯: {attack_scenario}, æ”»å‡»ç±»å‹: {attack_config['attack_type']}"
    print(attack_msg)
    add_log(attack_msg, "info")

    # Start federated learning
    avg_acc = [0]
    clients_list = summon_clients(args)
    
    # åˆå§‹åŒ–æ•°æ®æ”¶é›†å™¨
    experiment_name = f"XFL_SmallData_{attack_scenario}_defense_{args.enable_defense}"
    data_collector = initialize_data_collector(args, experiment_name)
    print(f"ğŸ“Š æ•°æ®æ”¶é›†å™¨å·²åˆå§‹åŒ–: {experiment_name}")
    client_models = []
    last_global_accuracy = 0.0  # è·Ÿè¸ªä¸Šä¸€è½®çš„å…¨å±€å‡†ç¡®ç‡
    
    for _iter in tqdm(range(args.epochs)):
        print('*' * 80)
        round_msg = f"Round {_iter:3d}"
        print(round_msg)
        add_log(round_msg, "round_start")

        w_locals = []
        lens = []
        current_round_models = []

        m = max(int(args.frac * args.num_users), 1)
        
        # å®¢æˆ·ç«¯é€‰æ‹©
        available_clients = list(range(args.num_users))
        np.random.shuffle(available_clients)
        selected_clients = available_clients[:m]
        
        # éªŒè¯å”¯ä¸€æ€§
        unique_clients = list(set(selected_clients))
        if len(unique_clients) != len(selected_clients):
            selected_clients = np.random.choice(
                range(args.num_users), min(m, args.num_users), replace=False
            ).tolist()
        
        print(f"this epoch choose: {selected_clients} (å…±{len(selected_clients)}ä¸ª)")
        print(f"XFL-SmallDataç®—æ³•: TEEä½¿ç”¨{tee_sample_ratio*100:.0f}%é‡‡æ ·æ•°æ®")

        # è®¾ç½®æ¶æ„å®¢æˆ·ç«¯
        attack_manager.setup_malicious_clients(selected_clients, _iter, args.epochs)
        
        if attack_manager.get_malicious_clients():
            malicious_list = sorted(attack_manager.get_malicious_clients())
            malicious_msg = f"ğŸš¨ æ¶æ„å®¢æˆ·ç«¯: {malicious_list}"
            print(malicious_msg)
            add_log(malicious_msg, "warning")
            tee_msg = "ğŸ”’ TEEä¿æŠ¤: æ¶æ„å®¢æˆ·ç«¯æ— æ³•æ±¡æŸ“TEEå†…éƒ¨è®­ç»ƒ"
            print(tee_msg)
            add_log(tee_msg, "info")
        
        for user_idx in selected_clients:
            # æ¸…ç†CUDAç¼“å­˜ï¼ˆé˜²æ­¢ç´¯ç§¯çš„å†…å­˜é—®é¢˜ï¼‰
            try:
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
            except:
                pass  # å¦‚æœCUDAå·²æŸåï¼Œè·³è¿‡æ¸…ç†
            
            local = LocalUpdate_XFL_SmallData(
                args=args, 
                dataset=dataset_train, 
                idxs=dict_users[user_idx], 
                verbose=True,
                tee_sample_ratio=tee_sample_ratio
            )
            
            try:
                # 1. å¤–éƒ¨è®­ç»ƒï¼šå®Œæ•´æ¨¡å‹ + å®Œæ•´æ•°æ®ï¼ˆå¯èƒ½è¢«æ±¡æŸ“ï¼‰
                external_model = copy.deepcopy(global_model).to(args.device)
                w_external, external_loss = local.train_external(
                    round=_iter,
                    external_model=external_model,
                    client_id=user_idx,
                    attack_manager=attack_manager
                )
                
                # âš ï¸ ä¸åˆ é™¤external_modelï¼Œä¿ç•™ç”¨äºåç»­æ£€æµ‹ï¼ˆé¿å…é‡å»ºï¼‰
                # è™½ç„¶ä¼šçŸ­æš‚ä¸tee_modelå…±å­˜ï¼Œä½†æ€»æ¯”510æ¬¡é‡å»ºå¥½
                
                # 2. TEEå†…éƒ¨è®­ç»ƒï¼šå®Œæ•´æ¨¡å‹ + é‡‡æ ·çš„å¹²å‡€æ•°æ®
                tee_model = copy.deepcopy(global_model).to(args.device)
                w_tee, Predict_loss = local.train_tee_secure(
                    round=_iter,
                    tee_model=tee_model,
                    client_id=user_idx,
                    attack_manager=attack_manager
                )
                    
                # 3. è®¡ç®—æŸå¤±
                external_loss_avg = external_loss / (args.local_ep * len(local.external_data))
                tee_loss_avg = Predict_loss / (local.tee_local_ep * len(local.clean_data))
                
                print(f"Client {user_idx} åŒæ¨¡å‹è®­ç»ƒå®Œæˆ:")
                print(f"   å¤–éƒ¨æ¨¡å‹æŸå¤±: {external_loss_avg:.6f} ({args.local_ep} epochs)")
                print(f"   TEEæ¨¡å‹æŸå¤±:  {tee_loss_avg:.6f} ({local.tee_local_ep} epochs)")
                print(f"   æŸå¤±å·®å¼‚:     {abs(external_loss_avg - tee_loss_avg):.6f}")
                
            except RuntimeError as e:
                if "CUDA" in str(e):
                    print(f"âŒ Client {user_idx} è®­ç»ƒå¤±è´¥ï¼ˆCUDAé”™è¯¯ï¼‰: {e}")
                    print(f"ğŸ’¥ CUDAé”™è¯¯æ£€æµ‹åˆ°ï¼Œç«‹å³åœæ­¢ç¨‹åºæ‰§è¡Œ")
                    print(f"ğŸ”§ å»ºè®®ï¼šé‡å¯Pythonè¿›ç¨‹æˆ–é‡å¯æœåŠ¡å™¨")
                    print(f"ğŸ“ é”™è¯¯ä½ç½®ï¼šRound {_iter}, Client {user_idx}")
                    raise e  # ç«‹å³æŠ›å‡ºé”™è¯¯ï¼Œåœæ­¢ç¨‹åº
                else:
                    raise e

            # èšåˆæ¨¡å‹ï¼ˆé›†æˆæ£€æµ‹å™¨å·²ç§»é™¤ï¼Œç›´æ¥èšåˆï¼‰
            is_malicious_actual = attack_manager and attack_manager.is_malicious(user_idx)
            w_locals.append(copy.deepcopy(w_external))
            lens.append(len(dict_users[user_idx]))
            current_round_models.append(copy.deepcopy(w_external))
            
            # æ¸…ç†å½“å‰å®¢æˆ·ç«¯çš„æ¨¡å‹
            if 'external_model' in locals():
                del external_model
            if 'tee_model' in locals():
                del tee_model
            try:
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
            except:
                pass  # CUDAä¸Šä¸‹æ–‡æŸåæ—¶ï¼Œæ¸…ç†æ“ä½œä¹Ÿä¼šå¤±è´¥
        
        client_models = current_round_models
        
        # èšåˆ
        if len(w_locals) == 0:
            print("âš ï¸  è­¦å‘Šï¼šæ‰€æœ‰å®¢æˆ·ç«¯éƒ½è¢«æ£€æµ‹ä¸ºæ¶æ„ï¼Œè·³è¿‡æœ¬è½®èšåˆ")
        else:
            try:
                # å°è¯•èšåˆï¼ˆå¯èƒ½å› CUDAä¸Šä¸‹æ–‡æŸåå¤±è´¥ï¼‰
                w_glob = Aggregation(w_locals, lens)
                global_model.load_state_dict(w_glob)
            except RuntimeError as e:
                if "CUDA" in str(e):
                    print(f"âŒ èšåˆå¤±è´¥ï¼ˆCUDAé”™è¯¯ï¼‰: {e}")
                    print(f"ğŸ’¥ CUDAé”™è¯¯æ£€æµ‹åˆ°ï¼Œç«‹å³åœæ­¢ç¨‹åºæ‰§è¡Œ")
                    print(f"ğŸ”§ å»ºè®®ï¼šé‡å¯Pythonè¿›ç¨‹æˆ–é‡å¯æœåŠ¡å™¨")
                    print(f"ğŸ“ é”™è¯¯ä½ç½®ï¼šRound {_iter}, èšåˆé˜¶æ®µ")
                    raise e  # ç«‹å³æŠ›å‡ºé”™è¯¯ï¼Œåœæ­¢ç¨‹åº
                else:
                    raise e
        
        # æµ‹è¯•
        accDict = {}
        try:
            if len(w_locals) > 0:
                global_accuracy = test(global_model, dataset_test, args)
                accDict[f"global-acc"] = global_accuracy
                last_global_accuracy = global_accuracy  # æ›´æ–°ä¸Šä¸€è½®å‡†ç¡®ç‡
                acc_msg = f"Round {_iter}: Global Model Accuracy = {global_accuracy:.2f}%"
                print(acc_msg)
                add_log(acc_msg, "accuracy")
            else:
                global_accuracy = test(global_model, dataset_test, args)
                accDict[f"global-acc"] = global_accuracy
                last_global_accuracy = global_accuracy  # æ›´æ–°ä¸Šä¸€è½®å‡†ç¡®ç‡
                acc_msg = f"Round {_iter}: Global Model Accuracy = {global_accuracy:.2f}% (æœªæ›´æ–°)"
                print(acc_msg)
                add_log(acc_msg, "accuracy")
        except RuntimeError as e:
            if "CUDA" in str(e):
                print(f"âŒ æµ‹è¯•å¤±è´¥ï¼ˆCUDAé”™è¯¯ï¼‰: {e}")
                print(f"ğŸ’¥ CUDAé”™è¯¯æ£€æµ‹åˆ°ï¼Œç«‹å³åœæ­¢ç¨‹åºæ‰§è¡Œ")
                print(f"ğŸ”§ å»ºè®®ï¼šé‡å¯Pythonè¿›ç¨‹æˆ–é‡å¯æœåŠ¡å™¨")
                print(f"ğŸ“ é”™è¯¯ä½ç½®ï¼šRound {_iter}, æµ‹è¯•é˜¶æ®µ")
                raise e  # ç«‹å³æŠ›å‡ºé”™è¯¯ï¼Œåœæ­¢ç¨‹åº
            else:
                raise e
        
        # æ”¶é›†æ•°æ®
        collect_round_data(_iter, accDict)
        upload_data(args, run, _iter, accDict, avg_acc, {"tee_sample_ratio": tee_sample_ratio})
        
        # âœ… æ¯è½®ç»“æŸåå½»åº•æ¸…ç†GPUå†…å­˜ï¼ˆé˜²æ­¢ç´¯ç§¯å¯¼è‡´å´©æºƒï¼‰
        try:
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()  # åŒæ­¥æ‰€æœ‰CUDAæ“ä½œ
                # æ¯10è½®æ‰“å°ä¸€æ¬¡GPUå†…å­˜çŠ¶æ€
                if _iter % 10 == 0:
                    allocated = torch.cuda.memory_allocated() / 1024**3
                    reserved = torch.cuda.memory_reserved() / 1024**3
                    print(f"  ğŸ’¾ GPUå†…å­˜: {allocated:.2f}GB / {reserved:.2f}GB")
        except:
            pass
    
    # è®­ç»ƒå®Œæˆ
    final_accuracy = accDict.get('global-acc', 0.0)
    
    summary_msg = f"\nğŸ”’ XFL-SmallData TEEå®‰å…¨è®­ç»ƒå®Œæˆ"
    print(summary_msg)
    add_log(summary_msg, "summary")
    
    final_acc_msg = f"  æœ€ç»ˆå‡†ç¡®ç‡: {final_accuracy:.4f}"
    print(final_acc_msg)
    add_log(final_acc_msg, "summary")
    
    tee_features = [
        "  TEE-SmallDataç‰¹æ€§:",
        f"    âœ… TEEé‡‡æ ·æ•°æ® - èŠ‚çœ{(1-tee_sample_ratio)*100:.0f}%å­˜å‚¨å’Œè®¡ç®—",
        f"    âœ… è°ƒæ•´è®­ç»ƒè½®æ¬¡ - ä¿æŒæ£€æµ‹æ•ˆæœ",
        "    âœ… å®Œæ•´æ¨¡å‹è®­ç»ƒ - æ— å‰ªææ€§èƒ½æŸå¤±",
        "    âœ… å¹²å‡€æ•°æ®ä¿æŠ¤ - ä¸å—å¤–éƒ¨æ”»å‡»æ±¡æŸ“",
        "    âœ… å†…éƒ¨å®‰å…¨æ£€æµ‹ - åŸºäºå®Œæ•´æ¨¡å‹ç‰¹å¾",
        "    âœ… é›¶ä¿¡ä»»æ¶æ„ - æ‰€æœ‰å®¢æˆ·ç«¯éƒ½éœ€éªŒè¯"
    ]
    for feature in tee_features:
        print(feature)
        add_log(feature, "summary")
    
    # ä¿å­˜æ•°æ®
    data_file = save_experiment_data()
    save_msg = f"ğŸ“Š å®éªŒæ•°æ®å·²ä¿å­˜: {data_file}"
    print(save_msg)
    add_log(save_msg, "info")
    
    endrun(run)

